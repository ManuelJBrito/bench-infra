# SPEC LLVM Benchmark

This repository contains infrastructure to build and run **GVN-related benchmarks** using [SPEC CPU2017](https://www.spec.org/cpu2017/), [LLVMâ€™s test-suite](https://llvm.org/docs/TestSuiteGuide.html), and custom GVN variants across multiple machines. It also includes previously collected results.

---

## Requirements

- [LLVM test-suite](https://llvm.org/docs/TestSuiteGuide.html)
- [llvm-lit](https://llvm.org/docs/CommandGuide/lit.html) (from an LLVM build or installable via `pip`)
- [SPEC CPU2017](https://www.spec.org/cpu2017/)

---

## Getting Started

```bash
# Clone this repository
git clone https://github.com/ManuelJBrito/bench-infra
cd bench-infra

# Get the LLVM test-suite
git clone https://github.com/llvm/llvm-test-suite.git test-suite

# Symlink your SPEC2017 installation
ln -s /full/path/to/cpu2017 test-suite/test-suite-externals/speccpu2017

# Generate scripts/common.sh (env setup)
# see -h for all options
chmod +x ./autogen.sh
./autogen.sh --cc /path/to/clang --lit /path/to/llvm-lit  
```

---

## Building SPEC Benchmarks

To compile SPEC benchmarks for a specific variant (e.g., `O2`), first define the variant:

```bash
echo '{"FLAGS" : "-O2"}' > variants/O2.json
```

Then build using:

```bash
chmod +x ./scripts/build_variant.sh
./scripts/build_variant.sh O2 test
```

- Use the `test` runtype first to validate the configuration.
- Once stable, use `ref` runtype for meaningful benchmarking.

---

## Running SPEC Benchmarks

After building a variant:

```bash
./scripts/run_variant.sh O2
```

This runs the tests `RUNS` number of times and outputs results in:

```
results/<machine-name>/O2/<timestamp>/result_run{i}.json
```

---

## Comparing Results

To merge and compare results, use the test-suite utility:

```bash
python3 test-suite/utils/compare.py result_run1.json result_run2.json ...
```

ğŸ“ *TODO*: Add helper scripts to automate merging and summarizing results.

---

## File Structure

```text
bench-infra/
â”œâ”€â”€ autogen.sh                 # Top-level script to generate common.sh
â”œâ”€â”€ builds/                    # Default build output directory (can be renamed)
â”‚   â”œâ”€â”€ O2/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ results/                   # Benchmark outputs
â”‚   â”œâ”€â”€ machine1/
â”‚   â”‚   â”œâ”€â”€ O2/
â”‚   â”‚   â”‚   â”œâ”€â”€ <timestamp>/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ result_run1.json
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ machineN/
â”œâ”€â”€ scripts/                   # Helper scripts
â”‚   â”œâ”€â”€ build_variant.sh       # Build benchmarks for a variant
â”‚   â”œâ”€â”€ run_variant.sh         # Run benchmarks and store results
â”‚   â””â”€â”€ common.sh              # Auto-generated by autogen.sh (env setup)
â”œâ”€â”€ test-suite/                # LLVM test-suite (cloned)
â”‚   â””â”€â”€ test-suite-externals/
â”‚       â””â”€â”€ speccpu2017 -> /path/to/cpu2017
â””â”€â”€ variants/                  # Benchmark variants (optimization configs)
    â”œâ”€â”€ O2.json
    â”œâ”€â”€ optFoo.json
    â””â”€â”€ ...
```
